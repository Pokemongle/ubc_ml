{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e944fb01",
   "metadata": {},
   "source": [
    "# 1. head files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472a75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autograd import grad\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc2a61",
   "metadata": {},
   "source": [
    "# 2. import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e224794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ubc_ml/lib/python3.8/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5141e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape:(70000, 784)\n",
      "labels: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n"
     ]
    }
   ],
   "source": [
    "print(f\"feature shape:{mnist.data.shape}\")\n",
    "print(f\"labels: {np.unique(mnist.target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff91954",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mnist.data\n",
    "# very important !!! str->int (do not use np.uint8, will overflow!)\n",
    "y = mnist.target.astype(int) \n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e074c8eb",
   "metadata": {},
   "source": [
    "## digit image example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450e4526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image pixel range: 0.0, 255.0\n",
      "labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "number 0: 6903 images\n",
      "number 1: 7877 images\n",
      "number 2: 6990 images\n",
      "number 3: 7141 images\n",
      "number 4: 6824 images\n",
      "number 5: 6313 images\n",
      "number 6: 6876 images\n",
      "number 7: 7293 images\n",
      "number 8: 6825 images\n",
      "number 9: 6958 images\n"
     ]
    }
   ],
   "source": [
    "print(f\"image pixel range: {x.min()}, {x.max()}\")\n",
    "x = x / x.max() # normalization\n",
    "print(f\"labels: {np.unique(y)}\")\n",
    "for i in range(10):\n",
    "    y_copy = y.copy()\n",
    "    print(f\"number {i}: {y_copy[y_copy==i].size} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f5c1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x344b114c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_sample = x[0].reshape(28,28)\n",
    "plt.matshow(image_sample, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05734081",
   "metadata": {},
   "source": [
    "# 3. split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4627014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape: ((56000, 784), (56000, 1))\n",
      "test set shape: ((14000, 784), (14000, 1))\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=seed, shuffle=True)\n",
    "print(f\"train set shape: {x_train.shape, y_train.shape}\")\n",
    "print(f\"test set shape: {x_test.shape, y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52d668",
   "metadata": {},
   "source": [
    "# 4. train model for C classes (C=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce79cf86",
   "metadata": {},
   "source": [
    "## define model, cost, optimization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f112a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_LogisticRegression:\n",
    "    def __init__(self, alpha=1.0, max_its=100, eps=1e-6):\n",
    "        \"\"\"\n",
    "        alpha: learning rate\n",
    "        max_its: max iteration of the training process\n",
    "        n_dim: dimension of feature\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.max_its = max_its\n",
    "        self.eps = eps\n",
    "        self.coef = None\n",
    "        self.bias = None\n",
    "        self.w = None\n",
    "        self.cost_history = None\n",
    "\n",
    "    def gradient_descent(self, cost_func, alpha, max_its, w, eps, decay=True):\n",
    "        gradient = grad(cost_func)\n",
    "        weight_history = [w]\n",
    "        cost_history = [cost_func(w)]\n",
    "        step_size = alpha\n",
    "        for k in range(max_its):\n",
    "            grad_eval = gradient(w)\n",
    "            if decay:\n",
    "                step_size = alpha / (k + 1)\n",
    "            w = w - step_size * grad_eval / np.linalg.norm(grad_eval)\n",
    "            weight_history.append(w)\n",
    "            cost = cost_func(w)\n",
    "            cost_history.append(cost)\n",
    "            if cost < eps or k >= max_its:\n",
    "                break\n",
    "        return w, weight_history, cost_history\n",
    "    \n",
    "    def softmax_loss(self, w, x, y):\n",
    "        \"\"\"\n",
    "        2-classification softmax\n",
    "        label:{-1, 1}\n",
    "        loss = \\frac{1}{P}\\Sigma_{p=1}^{P}log(1+e^{-y\\overline{x}_p^Tw})\n",
    "        \"\"\"\n",
    "        loss = np.log(1 + np.exp(-y * self.model(x, w)))\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def model(self, x_p, w):\n",
    "        \"\"\"\n",
    "        linear model\n",
    "        \"\"\"\n",
    "        # w0 + w1 * x\n",
    "        a = w[0] + np.dot(x_p, w[1:])\n",
    "        return a\n",
    "\n",
    "    def fit(self, x, y, opt='gradient_descent', cost_func='softmax'):\n",
    "        \"\"\"\n",
    "        Train Logistic Regression\n",
    "        opt: optimization method, default: gradient_descent\n",
    "        cost_func: cost function, default: softmax (label:{-1,1})\n",
    "        \"\"\"   \n",
    "        w = 2 * np.random.rand(x.shape[1]+1, 1) - 1    \n",
    "        # cost function\n",
    "        if cost_func == 'softmax':\n",
    "            c = lambda w: self.softmax_loss(w, x, y)\n",
    "        \n",
    "        # optimization method\n",
    "        if opt=='gradient_descent':\n",
    "            opt_method=self.gradient_descent\n",
    "        \n",
    "        # training process \n",
    "        final_weights, weight_history, cost_history = opt_method(c, self.alpha, self.max_its, w, self.eps)\n",
    "        self.w = final_weights\n",
    "        self.coef = final_weights[1:]\n",
    "        self.bias = final_weights[0]\n",
    "        self.cost_history = cost_history\n",
    "        return final_weights, weight_history, cost_history\n",
    "\n",
    "    def predict_class(self, x):\n",
    "        score = self.model(x, self.w)\n",
    "        return np.where(score>=0, 1, -1)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        score = self.model(x, self.w)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad57c7",
   "metadata": {},
   "source": [
    "## training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b2945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for class 0: 0.04397892819729113\n",
      "Cost for class 1: 0.035969401644275076\n",
      "Cost for class 2: 0.1067571003518268\n",
      "Cost for class 3: 0.11426036606566292\n",
      "Cost for class 4: 0.08121533768063721\n",
      "Cost for class 5: 0.12403342120544465\n",
      "Cost for class 6: 0.05370009132762576\n",
      "Cost for class 7: 0.06843675236314216\n",
      "Cost for class 8: 0.20962387161103063\n",
      "Cost for class 9: 0.1396914931093961\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "C = 10\n",
    "for c in range(C):\n",
    "    x = x_train\n",
    "    y = y_train.copy()\n",
    "    y[y_train==c]=1\n",
    "    y[y_train!=c]=-1\n",
    "    model = My_LogisticRegression(alpha=1.0, max_its=1000, eps=1e-4)\n",
    "    model.fit(x, y)\n",
    "    print(f\"Cost for class {c}: {model.cost_history[-1]}\")\n",
    "    model_list.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51154016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Accuracy on train set====\n",
      "Correct predictions: 48884\n",
      "Accuracy: 0.8729285714285714\n"
     ]
    }
   ],
   "source": [
    "d = None\n",
    "for c in range(10):\n",
    "    x = x_train.copy()\n",
    "    model = model_list[c]\n",
    "    if c == 0:\n",
    "        d = model.predict(x)\n",
    "    else:\n",
    "        d = np.concatenate((d, model.predict(x)), axis=1)\n",
    "\n",
    "z = np.argmax(d, axis=1)\n",
    "z=z.reshape(-1,1)\n",
    "print(f\"====Accuracy on train set====\")\n",
    "print(f\"Correct predictions: {np.sum(z==y_train)}\")\n",
    "print(f\"Accuracy: {np.sum(z==y_train)/y_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbc6f1",
   "metadata": {},
   "source": [
    "## test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1384be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set\n",
      "Correct predictions: 12254\n",
      "Accuracy: 0.8752857142857143\n"
     ]
    }
   ],
   "source": [
    "d = None\n",
    "\n",
    "for c in range(10):\n",
    "    x = x_test.copy()\n",
    "    model = model_list[c]\n",
    "    if c == 0:\n",
    "        d = model.predict(x)\n",
    "    else:\n",
    "        d = np.concatenate((d, model.predict(x)), axis=1)\n",
    "z = np.argmax(d, axis=1)\n",
    "z=z.reshape(-1,1)\n",
    "print(f\"Accuracy on test set\")\n",
    "print(f\"Correct predictions: {np.sum(z==y_test)}\")\n",
    "print(f\"Accuracy: {np.sum(z==y_test)/y_test.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubc_ml",
   "language": "python",
   "name": "ubc_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
