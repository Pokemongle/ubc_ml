{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc945c39-f9c2-43c4-ab72-3f4fefdd6a89",
   "metadata": {},
   "source": [
    "# 1. Headfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d302fcb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcdd070-8b4c-4968-890e-c33c3d529aa4",
   "metadata": {},
   "source": [
    "# 2. Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ac1ea-b76d-4859-8983-f5ce310d4c4d",
   "metadata": {},
   "source": [
    "## check the data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d24b1b-4239-4038-b81c-717ed823b2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ shapes ============\n",
      "shape: (1030, 9)\n",
      "============ infos ============\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Cement               1030 non-null   float64\n",
      " 1   BlastFurnaceSlag     1030 non-null   float64\n",
      " 2   FlyAsh               1030 non-null   float64\n",
      " 3   Water                1030 non-null   float64\n",
      " 4   Superplasticizer     1030 non-null   float64\n",
      " 5   CoarseAggregate      1030 non-null   float64\n",
      " 6   FineAggregate        1030 non-null   float64\n",
      " 7   Age                  1030 non-null   int64  \n",
      " 8   CompressiveStrength  1030 non-null   float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 72.5 KB\n"
     ]
    }
   ],
   "source": [
    "# load and shape \n",
    "df = pd.read_csv('archive/concrete.csv')\n",
    "# print(df)\n",
    "print(f'============ shapes ============')\n",
    "print(f'shape: {df.shape}')\n",
    "print(f'============ infos ============')\n",
    "df.info()\n",
    "# print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf3c94-0b39-4961-98db-dfaab2894804",
   "metadata": {},
   "source": [
    "## check missing data and duplicated lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1295aa-be31-4176-ada5-5235001bd9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ has duplicates ===========\n",
      "dataset has duplicates: True\n",
      "There are 25 duplicated lines\n",
      "============ has missing data ===========\n",
      "dataset has missing data: False\n",
      "Cement                 0\n",
      "BlastFurnaceSlag       0\n",
      "FlyAsh                 0\n",
      "Water                  0\n",
      "Superplasticizer       0\n",
      "CoarseAggregate        0\n",
      "FineAggregate          0\n",
      "Age                    0\n",
      "CompressiveStrength    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'============ has duplicates ===========')\n",
    "print(f'dataset has duplicates: {df.duplicated().any()}')\n",
    "print(f'There are {df.duplicated().sum()} duplicated lines')\n",
    "print(f'============ has missing data ===========')\n",
    "print(f'dataset has missing data: {df.isna().any().any()}')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd3f56-8c03-4e4f-a6d6-b3648f1c54d5",
   "metadata": {},
   "source": [
    "## clean missing and duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5259129b-d639-4f78-8d25-e52e36e65fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated lines after cleaning\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.drop_duplicates()\n",
    "print(f'There are {df_clean.duplicated().sum()} duplicated lines after cleaning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3ce64-48a0-4c7f-ba84-37c96bea87a0",
   "metadata": {},
   "source": [
    "## check outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a75d63-17ef-4ad8-9f87-c4a9f5743878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49 lines having outliers(thresh=3.0)\n",
      "shape of dataset after cleaning outliers: (956, 9)\n"
     ]
    }
   ],
   "source": [
    "# zscore \n",
    "df_zscore = df_clean.copy()\n",
    "thresh = 3.0\n",
    "df_zscore = (df_zscore - df_zscore.mean()) / df_zscore.std()\n",
    "df_outliner = df_zscore.abs() > thresh\n",
    "# print(df_outliner)\n",
    "row_has_outlier = df_outliner.any(axis=1)\n",
    "print(f'There are {row_has_outlier.sum()} lines having outliers(thresh={thresh})')\n",
    "df_final = df_clean.loc[~row_has_outlier].copy()\n",
    "print(f\"shape of dataset after cleaning outliers: {df_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc84ca99-ebb6-4a07-9b96-3782f85f6e11",
   "metadata": {},
   "source": [
    "# 3. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96a320-13b1-4e18-91ab-c7790b680252",
   "metadata": {},
   "source": [
    "## split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2123849c-ce0d-46d8-8f8a-131050827777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (956, 8)\n",
      "output shape: (956,)\n",
      "train input shape:  (764, 8)\n",
      "train output shape: (192, 8)\n",
      "test input shape:   (764,)\n",
      "test output shape:  (192,)\n"
     ]
    }
   ],
   "source": [
    "X = df_final.drop(columns=['CompressiveStrength']).values\n",
    "y = df_final['CompressiveStrength'].values\n",
    "print(f'input shape: {X.shape}')\n",
    "print(f'output shape: {y.shape}')\n",
    "\n",
    "seed = 32\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state=seed\n",
    ")\n",
    "print(f'train input shape:  {X_train.shape}')\n",
    "print(f'train output shape: {X_test.shape}')\n",
    "print(f'test input shape:   {y_train.shape}')\n",
    "print(f'test output shape:  {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a67023-0e84-44d8-ae78-74301b40362d",
   "metadata": {},
   "source": [
    "- task b: Calculate the linear regression model parameters that minimize MSE on the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a0ac56-f7f5-4703-9cbc-e33f172cf2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias: 6.86616680082108\n",
      "weights: [ 0.11020514  0.08777844  0.0629237  -0.17754718  0.38681716  0.0040966\n",
      "  0.00714792  0.21685304]\n",
      "number of parameters: 9\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"bias: {model.intercept_}\")\n",
    "print(f\"weights: {model.coef_}\")\n",
    "print(f\"number of parameters: {len(model.coef_) + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d552e-9c4f-4627-b692-6484cdf43b01",
   "metadata": {},
   "source": [
    "# 4. Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a59165-1d18-458e-8750-a453064dc9ea",
   "metadata": {},
   "source": [
    "- task c. Report the test MSE of your linear regression model.\n",
    "- task d. Report the R2 coefficient of your model on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5445376-8d2d-4e12-84ab-e203ed2616af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 76.11834841285956\n",
      "R2: 0.723595456980569\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"MSE: {mse_test}\")\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(f\"R2: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b7295b-759f-40b0-b607-963e714eb2d5",
   "metadata": {},
   "source": [
    "# task e. data normalization and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dceb10bb-8a4c-4787-99b8-cc84bbef1477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias: 34.62915770294921\n",
      "weights: [11.26465128  7.46024179  4.0634448  -3.56887083  2.09187325  0.31750076\n",
      "  0.55576     8.01509665]\n",
      "number of parameters: 9\n",
      "MSE scaled: 76.11834841285958\n",
      "R2 scaled: 0.7235954569805689\n"
     ]
    }
   ],
   "source": [
    "X = df_final.drop(columns=['CompressiveStrength']).values\n",
    "y = df_final['CompressiveStrength'].values\n",
    "X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "seed = 32\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size = 0.2, random_state=seed\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"bias: {model.intercept_}\")\n",
    "print(f\"weights: {model.coef_}\")\n",
    "print(f\"number of parameters: {len(model.coef_) + 1}\")\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "print(f'MSE scaled: {mse_test}')\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(f'R2 scaled: {r2_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb718a-5c89-43a7-936c-c8c44a501d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d552360c-de30-4826-a368-7dd607d67fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d520ca1-7af2-4736-9291-55df5c6076a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubc_ml",
   "language": "python",
   "name": "ubc_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
